{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files (path_file):\n",
    "    story = open(path_file, encoding = 'utf-8')\n",
    "    file_text = story.read()\n",
    "    story.close()\n",
    "    return file_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_summary (file_text):\n",
    "    \n",
    "    file_text = file_text.replace('\\n',' ').replace(\"\\'\",\"\")\n",
    "    start_summary = file_text.find('@highlight') #summaries are identified by '@highlight'\n",
    "    article = file_text[:start_summary]\n",
    "    summary = file_text[start_summary+len('@highlight'):]\n",
    "\n",
    "    summaries_list = summary.split('@highlight')\n",
    "    summaries_list = [summ.strip() for summ in summaries_list]\n",
    "\n",
    "    summaries_text = summary.replace('@highlight', '. ').strip()\n",
    "\n",
    "    return article, summaries_text, summaries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback( str ):\n",
    "    return str.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (stories_directory):\n",
    "    articles = []\n",
    "    summary_text = []\n",
    "    summary_list = []\n",
    "    \n",
    "    i=0\n",
    "    for filename in os.listdir(stories_directory)[:20000]:\n",
    "        #print(filename)\n",
    "        \n",
    "        path = stories_directory + '/'+ filename\n",
    "        file_text = load_files(path)\n",
    "        article, summaries_text, summaries_list = article_summary(file_text)\n",
    "\n",
    "        if len(article) != 0:\n",
    "            print(i)\n",
    "            article = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ', str(article)) #remove website like 'http://website.com'\n",
    "            article = re.sub(r'www[\\s]?[.][\\s]?(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', ' ', str(article)) #remove website like 'www.website.com'\n",
    "            article = re.sub(r'[\\(|\\[]?[A-Za-z]+\\.com[\\s|\\)|\\]]', ' ', str(article)) #remove website like 'website.com'\n",
    "            article = re.sub(r'[0-9]+\\s?[.]\\s?[0-9]+', 'xxxx', article) #remove decimal numbers\n",
    "            article = re.sub(r'\\b([a-zA-Z]\\.)([a-zA-Z]\\.)+', lambda m: callback(m.group()), article) #acronimi\n",
    "            article = article.replace('.', '. ')\n",
    "            articles.append(article)\n",
    "            summary_text.append(summaries_text)\n",
    "            summary_list.append(summaries_list)\n",
    "\n",
    "\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data['article'] = articles\n",
    "    data['summary_string'] = summary_text\n",
    "    data['summary_list'] = summary_list\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "source": [
    "data = load_data('D:/UNIVERSITA_2/Magistrale/TextMining/PROGETTO_text_mining/cnn_stories/cnn/stories')\n",
    "data.to_csv('article_summaries_noNaN_prep_20000_2.csv')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}